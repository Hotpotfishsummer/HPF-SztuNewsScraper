#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Dify å·¥ä½œæµå¯¹æ¥æ¨¡å— - æ–°é—»ç›¸å…³æ€§åˆ†æ
å¯¹æ¥ Dify å·¥ä½œæµï¼Œæ¥æ”¶ç”¨æˆ·èµ„æ–™å’Œæ–°é—»æ–‡ä»¶ï¼Œè¿”å›ç»“æ„åŒ–çš„ç›¸å…³æ€§åˆ†æç»“æœ
"""

import json
import sys
import os
from typing import Dict, Any
from pathlib import Path
from datetime import datetime

# æ·»åŠ  src ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from config import get_config
from logger_config import get_logger
from ai.dify_client import DifyClient

logger = get_logger(__name__)


class DifyWorkflowHandler:
    """å¤„ç† Dify å·¥ä½œæµçš„è¾“å…¥è¾“å‡º"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµå¤„ç†å™¨"""
        self.config = get_config()
        self.logger = logger
        self.dify_client = DifyClient()
    
    def validate_inputs(self, user_profile_str: str, news_file_path: str) -> Dict[str, Any]:
        """
        éªŒè¯è¾“å…¥å‚æ•°
        
        Args:
            user_profile_str: ç”¨æˆ·èµ„æ–™çš„ JSON å­—ç¬¦ä¸²
            news_file_path: æ–°é—»æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«éªŒè¯ç»“æœå’Œè§£ææ•°æ®çš„å­—å…¸
        """
        validation_result = {
            'valid': True,
            'errors': [],
            'user_profile': None,
            'news_data': None
        }
        
        # éªŒè¯ç”¨æˆ·èµ„æ–™ JSON å­—ç¬¦ä¸²
        try:
            user_profile = json.loads(user_profile_str)
            validation_result['user_profile'] = user_profile
            self.logger.info("âœ… ç”¨æˆ·èµ„æ–™ JSON è§£ææˆåŠŸ")
        except json.JSONDecodeError as e:
            validation_result['valid'] = False
            validation_result['errors'].append(f"ç”¨æˆ·èµ„æ–™ JSON è§£æå¤±è´¥: {str(e)}")
            self.logger.error(f"âŒ ç”¨æˆ·èµ„æ–™æ ¼å¼é”™è¯¯: {str(e)}")
        
        # éªŒè¯æ–°é—»æ–‡ä»¶
        if not os.path.exists(news_file_path):
            validation_result['valid'] = False
            validation_result['errors'].append(f"æ–°é—»æ–‡ä»¶ä¸å­˜åœ¨: {news_file_path}")
            self.logger.error(f"âŒ æ–°é—»æ–‡ä»¶ä¸å­˜åœ¨: {news_file_path}")
        else:
            try:
                with open(news_file_path, 'r', encoding='utf-8') as f:
                    news_data = json.load(f)
                validation_result['news_data'] = news_data
                self.logger.info("âœ… æ–°é—»æ–‡ä»¶è§£ææˆåŠŸ")
            except json.JSONDecodeError as e:
                validation_result['valid'] = False
                validation_result['errors'].append(f"æ–°é—»æ–‡ä»¶ JSON è§£æå¤±è´¥: {str(e)}")
                self.logger.error(f"âŒ æ–°é—»æ–‡ä»¶æ ¼å¼é”™è¯¯: {str(e)}")
            except Exception as e:
                validation_result['valid'] = False
                validation_result['errors'].append(f"è¯»å–æ–°é—»æ–‡ä»¶å¤±è´¥: {str(e)}")
                self.logger.error(f"âŒ è¯»å–æ–°é—»æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return validation_result
    
    def process_workflow(self, user_profile_str: str, news_file_path: str) -> str:
        """
        å¤„ç† Dify å·¥ä½œæµ
        
        Args:
            user_profile_str: ç”¨æˆ·èµ„æ–™çš„ JSON å­—ç¬¦ä¸²
            news_file_path: æ–°é—»æ–‡ä»¶è·¯å¾„
            
        Returns:
            JSON æ ¼å¼çš„åˆ†æç»“æœå­—ç¬¦ä¸²
        """
        # éªŒè¯è¾“å…¥
        validation = self.validate_inputs(user_profile_str, news_file_path)
        
        if not validation['valid']:
            error_response = {
                'status': 'error',
                'message': 'è¾“å…¥éªŒè¯å¤±è´¥',
                'errors': validation['errors']
            }
            self.logger.error(f"âŒ å·¥ä½œæµå¤„ç†å¤±è´¥: {validation['errors']}")
            return json.dumps(error_response, ensure_ascii=False)
        
        try:
            user_profile = validation['user_profile']
            news_data = validation['news_data']
            
            # æå–å¿…éœ€çš„æ–°é—»å­—æ®µ
            title = news_data.get('title', '')
            content = news_data.get('content', '')
            
            if not title or not content:
                error_response = {
                    'status': 'error',
                    'message': 'æ–°é—»æ–‡ä»¶ç¼ºå°‘å¿…éœ€å­—æ®µ (title, content)',
                    'received_keys': list(news_data.keys())
                }
                self.logger.error("âŒ æ–°é—»æ•°æ®ç¼ºå°‘å¿…éœ€å­—æ®µ")
                return json.dumps(error_response, ensure_ascii=False)
            
            # æ£€æŸ¥ Dify æ˜¯å¦å¯ç”¨
            if self.config.dify_enabled:
                # ä¼ é€’æ–‡ä»¶è·¯å¾„ç»™ Dify API
                return self._call_dify_api(user_profile, news_data, news_file_path)
            else:
                # å¦‚æœ Dify æœªå¯ç”¨ï¼Œè¿”å›å‡†å¤‡å¥½çš„æ•°æ®
                return self._prepare_workflow_result(user_profile, title, content, news_file_path)
        
        except Exception as e:
            error_response = {
                'status': 'error',
                'message': f'å·¥ä½œæµå¤„ç†å¼‚å¸¸: {str(e)}'
            }
            self.logger.error(f"âŒ å·¥ä½œæµå¤„ç†å¼‚å¸¸: {str(e)}")
            return json.dumps(error_response, ensure_ascii=False)
    
    def _call_dify_api(self, user_profile: Dict[str, Any], news_data: Dict[str, Any], news_file_path: str) -> str:
        """
        è°ƒç”¨ Dify API è¿›è¡Œå·¥ä½œæµå¤„ç†
        
        Args:
            user_profile: ç”¨æˆ·èµ„æ–™å­—å…¸
            news_data: æ–°é—»æ•°æ®å­—å…¸ï¼ˆå¤‡ç”¨ï¼Œå¦‚æœæ–‡ä»¶ä¸å¯ç”¨ï¼‰
            news_file_path: æ–°é—»æ–‡ä»¶è·¯å¾„ï¼ˆJSON æ–‡ä»¶ï¼‰
            
        Returns:
            JSON æ ¼å¼çš„åˆ†æç»“æœå­—ç¬¦ä¸²
        """
        try:
            # æ£€æŸ¥ Dify æ˜¯å¦é…ç½®
            if not self.dify_client.is_configured():
                error_response = {
                    'status': 'error',
                    'message': 'Dify API Key æœªé…ç½®'
                }
                self.logger.error("âŒ Dify API Key æœªé…ç½®")
                return json.dumps(error_response, ensure_ascii=False)
            
            # éªŒè¯æ–°é—»æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(news_file_path):
                error_response = {
                    'status': 'error',
                    'message': f'æ–°é—»æ–‡ä»¶ä¸å­˜åœ¨: {news_file_path}'
                }
                self.logger.error(f"âŒ {error_response['message']}")
                return json.dumps(error_response, ensure_ascii=False)
            
            # æ­¥éª¤ 1: ä¸Šä¼ æ–‡ä»¶åˆ° Dify è·å–æ–‡ä»¶ ID
            self.logger.info(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ° Dify: {news_file_path}")
            upload_result = self.dify_client.upload_file(news_file_path)
            
            if not upload_result:
                error_response = {
                    'status': 'error',
                    'message': 'æ–‡ä»¶ä¸Šä¼ åˆ° Dify å¤±è´¥'
                }
                self.logger.error("âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥")
                return json.dumps(error_response, ensure_ascii=False)
            
            file_id, detected_type = upload_result
            
            # æ­¥éª¤ 2: ä½¿ç”¨æ–‡ä»¶ ID è°ƒç”¨å·¥ä½œæµ
            self.logger.info(f"ğŸ”„ ä½¿ç”¨æ–‡ä»¶ ID è°ƒç”¨ Dify å·¥ä½œæµ")
            
            user_profile_json = json.dumps(user_profile, ensure_ascii=False)
            dify_response = self.dify_client.call_workflow(user_profile_json, file_id, detected_type)
            
            # è§£æ Dify å“åº”
            response_data = json.loads(dify_response)
            
            if response_data.get('status') == 'success':
                # æå–å¹¶éªŒè¯è¾“å‡º
                analysis_result = self.dify_client.extract_outputs(dify_response)
                validation_result = self.dify_client.validate_response(analysis_result)
                
                return json.dumps({
                    'status': 'success',
                    'data': analysis_result,
                    'dify_response_id': response_data.get('dify_response_id', ''),
                    'validation_warnings': validation_result.get('warnings', [])
                }, ensure_ascii=False)
            else:
                # Dify API é”™è¯¯
                return dify_response
        
        except Exception as e:
            error_response = {
                'status': 'error',
                'message': f'Dify API è°ƒç”¨å¼‚å¸¸: {str(e)}'
            }
            self.logger.error(f"âŒ Dify API è°ƒç”¨å¼‚å¸¸: {str(e)}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return json.dumps(error_response, ensure_ascii=False)
    
    def _prepare_workflow_result(self, user_profile: Dict[str, Any], 
                                 title: str, content: str, 
                                 news_file_path: str) -> str:
        """
        å‡†å¤‡å·¥ä½œæµç»“æœï¼ˆDify æœªå¯ç”¨æ—¶ï¼‰
        
        Args:
            user_profile: ç”¨æˆ·èµ„æ–™
            title: æ–°é—»æ ‡é¢˜
            content: æ–°é—»å†…å®¹
            news_file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            JSON æ ¼å¼çš„ç»“æœå­—ç¬¦ä¸²
        """
        result = {
            'status': 'pending_analysis',
            'message': 'ç­‰å¾… Dify å·¥ä½œæµå¤„ç†',
            'input_metadata': {
                'user_profile_provided': bool(user_profile),
                'news_title': title[:100],
                'news_content_length': len(content),
                'news_file_path': news_file_path,
                'processed_at': self._get_iso_timestamp()
            },
            'workflow_inputs': {
                'user_profile': user_profile,
                'news': {
                    'title': title,
                    'content': content,
                    'file_path': news_file_path
                }
            },
            'expected_output_schema': {
                'title': 'string (æ–‡ç« çš„æ ‡é¢˜)',
                'summary': 'string (æ–‡ç« å†…å®¹çš„ç®€æ˜æ€»ç»“)',
                'relevance_score': 'number (0-10ï¼Œ10è¡¨ç¤ºæœ€ç›¸å…³)',
                'relevance_reason': 'string (è¯„åˆ†åŸå› è¯´æ˜)'
            }
        }
        return json.dumps(result, ensure_ascii=False)
    
    def _prepare_analysis_data(self, user_profile: Dict[str, Any], 
                              title: str, content: str, 
                              news_file_path: str) -> Dict[str, Any]:
        """
        å‡†å¤‡åˆ†ææ•°æ®ä¾› Dify å·¥ä½œæµä½¿ç”¨
        
        Args:
            user_profile: ç”¨æˆ·èµ„æ–™å­—å…¸
            title: æ–°é—»æ ‡é¢˜
            content: æ–°é—»å†…å®¹
            news_file_path: æ–°é—»æ–‡ä»¶è·¯å¾„
            
        Returns:
            å‡†å¤‡å¥½çš„åˆ†ææ•°æ®
        """
        return {
            'status': 'pending_analysis',
            'message': 'ç­‰å¾… Dify å·¥ä½œæµå¤„ç†',
            'input_metadata': {
                'user_profile_provided': bool(user_profile),
                'news_title': title[:100],
                'news_content_length': len(content),
                'news_file_path': news_file_path,
                'processed_at': self._get_iso_timestamp()
            },
            'workflow_inputs': {
                'user_profile': user_profile,
                'news': {
                    'title': title,
                    'content': content,
                    'file_path': news_file_path
                }
            },
            'expected_output_schema': {
                'title': 'string (æ–‡ç« çš„æ ‡é¢˜)',
                'summary': 'string (æ–‡ç« å†…å®¹çš„ç®€æ˜æ€»ç»“)',
                'relevance_score': 'number (0-10ï¼Œ10è¡¨ç¤ºæœ€ç›¸å…³)',
                'relevance_reason': 'string (è¯„åˆ†åŸå› è¯´æ˜)'
            }
        }
    
    def parse_workflow_output(self, workflow_output_str: str) -> Dict[str, Any]:
        """
        è§£æ Dify å·¥ä½œæµçš„è¾“å‡º
        
        Args:
            workflow_output_str: å·¥ä½œæµè¿”å›çš„ JSON å­—ç¬¦ä¸²
            
        Returns:
            è§£æåçš„è¾“å‡ºå­—å…¸
        """
        try:
            output_data = json.loads(workflow_output_str)
            
            # éªŒè¯è¾“å‡ºåŒ…å«å¿…éœ€å­—æ®µ
            required_fields = ['title', 'summary', 'relevance_score', 'relevance_reason']
            missing_fields = [f for f in required_fields if f not in output_data]
            
            if missing_fields:
                self.logger.warning(f"âš ï¸ å·¥ä½œæµè¾“å‡ºç¼ºå°‘å­—æ®µ: {missing_fields}")
            
            # éªŒè¯ relevance_score çš„æœ‰æ•ˆæ€§
            if 'relevance_score' in output_data:
                try:
                    score = float(output_data['relevance_score'])
                    if not (0 <= score <= 10):
                        self.logger.warning(f"âš ï¸ ç›¸å…³æ€§è¯„åˆ†è¶…å‡ºèŒƒå›´: {score}")
                except (ValueError, TypeError):
                    self.logger.warning(f"âš ï¸ ç›¸å…³æ€§è¯„åˆ†æ ¼å¼é”™è¯¯: {output_data['relevance_score']}")
            
            return {
                'status': 'success',
                'data': output_data,
                'validation_warnings': missing_fields
            }
        
        except json.JSONDecodeError as e:
            self.logger.error(f"âŒ å·¥ä½œæµè¾“å‡º JSON è§£æå¤±è´¥: {str(e)}")
            return {
                'status': 'error',
                'message': f'è¾“å‡º JSON è§£æå¤±è´¥: {str(e)}',
                'raw_output': workflow_output_str
            }
    
    def _get_iso_timestamp(self) -> str:
        """è·å– ISO æ ¼å¼çš„æ—¶é—´æˆ³"""
        return datetime.now().isoformat()
