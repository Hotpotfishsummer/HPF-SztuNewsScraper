# éƒ¨ç½²æŒ‡å—

SZTU æ–°é—»çˆ¬è™«æ”¯æŒä¸¤ç§ä¸»è¦éƒ¨ç½²æ¨¡å¼ï¼š**CLI ç‰ˆæœ¬**ï¼ˆæœ¬åœ°äº¤äº’ï¼‰å’Œ **æœåŠ¡ç‰ˆæœ¬**ï¼ˆDocker åå°è¿è¡Œï¼‰ã€‚

## ç›®å½•

- [CLI ç‰ˆæœ¬éƒ¨ç½²](#cli-ç‰ˆæœ¬éƒ¨ç½²æœ¬åœ°äº¤äº’)
- [æœåŠ¡ç‰ˆæœ¬éƒ¨ç½²](#æœåŠ¡ç‰ˆæœ¬éƒ¨ç½²docker-åå°)
- [Docker Compose éƒ¨ç½²](#docker-compose-éƒ¨ç½²æ¨è)
- [é…ç½®ç®¡ç†](#é…ç½®ç®¡ç†)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## CLI ç‰ˆæœ¬éƒ¨ç½²ï¼ˆæœ¬åœ°äº¤äº’ï¼‰

### ç¯å¢ƒè¦æ±‚

- Python 3.8+
- Condaï¼ˆå¯é€‰ï¼‰

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/Hotpotfishsummer/HPF-SztuNewsScraper.git
cd HPF-SztuNewsScraper

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
conda env create -f environment.yml
conda activate hpf-sztu-scraper

# æˆ–ä½¿ç”¨ pipï¼š
pip install -r requirements.txt

# 3. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .envï¼Œå¡«å…¥å®é™…çš„ API Key å’Œé…ç½®

# 4. å¯åŠ¨ CLI
python cli_entry.py
```

### CLI å‘½ä»¤ç¤ºä¾‹

```bash
# å¯åŠ¨äº¤äº’èœå•
python cli_entry.py

# çˆ¬å–æ–°é—»
python cli_entry.py --fetch-json 5          # çˆ¬å– 5 é¡µï¼ˆJSON æ ¼å¼ï¼‰
python cli_entry.py --fetch-full 3          # çˆ¬å– 3 é¡µï¼ˆå®Œæ•´å†…å®¹ï¼‰

# æµè§ˆæ–‡ç« 
python cli_entry.py --list                  # åˆ—å‡ºæ‰€æœ‰æ–‡ç« 
python cli_entry.py --search-title "å…³é”®è¯" # æŒ‰æ ‡é¢˜æœç´¢

# å¯åŠ¨ Web UI
python cli_entry.py --web

# AI åˆ†æ
python cli_entry.py --analyze               # å¯åŠ¨ AI åˆ†ææ¨¡å¼

# æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
python cli_entry.py --info
```

---

## æœåŠ¡ç‰ˆæœ¬éƒ¨ç½²ï¼ˆDocker åå°ï¼‰

### ç¯å¢ƒè¦æ±‚

- Docker 20.10+
- Docker Compose 1.29+ï¼ˆå¯é€‰ï¼Œä½†æ¨èï¼‰

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/Hotpotfishsummer/HPF-SztuNewsScraper.git
cd HPF-SztuNewsScraper

# 2. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .envï¼Œå¡«å…¥å®é™…çš„é…ç½®

# 3. å¯åŠ¨æœåŠ¡ç‰ˆæœ¬
python service_entry.py

# æˆ–åœ¨åå°è¿è¡Œ
nohup python service_entry.py > logs/service.log 2>&1 &
```

### æœåŠ¡å‘½ä»¤ç¤ºä¾‹

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆæ¨èï¼‰
python service_entry.py

# ä»…å¯åŠ¨è°ƒåº¦å™¨
python service_entry.py --scheduler-only

# ä»…å¯åŠ¨ API
python service_entry.py --api-only

# ä»…å¯åŠ¨ Web UI
python service_entry.py --web-only

# æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
python service_entry.py --info
```

### è®¿é—®æ–¹å¼

- **Streamlit Web UI**: http://localhost:8501
- **FastAPI REST API**: http://localhost:8000
- **API æ–‡æ¡£**: http://localhost:8000/docs

---

## Docker Compose éƒ¨ç½²ï¼ˆæ¨èï¼‰

### ç¯å¢ƒè¦æ±‚

- Docker 20.10+
- Docker Compose 1.29+

### å¿«é€Ÿå¼€å§‹

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/Hotpotfishsummer/HPF-SztuNewsScraper.git
cd HPF-SztuNewsScraper

# 2. æ„å»ºé•œåƒ
docker-compose build

# 3. é…ç½®ç¯å¢ƒ
cp .env.example .env
# ç¼–è¾‘ .env

# 4. å¯åŠ¨æœåŠ¡
docker-compose up -d service

# 5. æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f service

# 6. åœæ­¢æœåŠ¡
docker-compose down
```

### éƒ¨ç½²é€‰é¡¹

#### é€‰é¡¹ 1: æœåŠ¡ç‰ˆæœ¬ï¼ˆæ¨èï¼‰

ä¸€ä¸ªå®¹å™¨è¿è¡Œæ‰€æœ‰æœåŠ¡ï¼ˆè°ƒåº¦å™¨ + API + Web UIï¼‰ï¼š

```bash
docker-compose up -d service
```

**ä¼˜ç‚¹ï¼š**
- ç®€å•æ˜“ç®¡ç†
- èµ„æºæ¶ˆè€—å°‘
- é€‚åˆå°åˆ°ä¸­å‹éƒ¨ç½²

#### é€‰é¡¹ 2: å¾®æœåŠ¡ç‰ˆæœ¬ï¼ˆé«˜çº§ï¼‰

å¤šä¸ªç‹¬ç«‹å®¹å™¨ï¼Œæ¯ä¸ªå®¹å™¨è¿è¡Œä¸€ä¸ªæœåŠ¡ï¼š

```bash
docker-compose --profile microservices up -d
```

å¯åŠ¨ 3 ä¸ªå®¹å™¨ï¼š
- `sztu-scraper-scheduler` - å®šæ—¶è°ƒåº¦å™¨
- `sztu-scraper-api` - FastAPI REST API
- `sztu-scraper-web` - Streamlit Web UI

**ä¼˜ç‚¹ï¼š**
- æ”¯æŒç‹¬ç«‹æ‰©å±•
- æœåŠ¡éš”ç¦»
- é€‚åˆå¤§å‹éƒ¨ç½²

#### é€‰é¡¹ 3: CLI ç‰ˆæœ¬

äº¤äº’å¼å‘½ä»¤è¡Œç‰ˆæœ¬ï¼ˆéœ€è¦ TTYï¼‰ï¼š

```bash
docker-compose run --rm cli
```

### Docker å‘½ä»¤ç¤ºä¾‹

```bash
# å¯åŠ¨ç‰¹å®šæœåŠ¡
docker-compose up -d service

# å¯åŠ¨å¾®æœåŠ¡
docker-compose --profile microservices up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f [service_name]
docker-compose logs service -f --tail 100

# æ‰§è¡Œå‘½ä»¤
docker-compose exec service python cli_entry.py --list

# åœæ­¢æœåŠ¡
docker-compose stop
docker-compose down                # åˆ é™¤å®¹å™¨
docker-compose down -v             # åˆ é™¤å®¹å™¨å’Œå·

# é‡å¯æœåŠ¡
docker-compose restart service
```

### æ•°æ®æŒä¹…åŒ–

é€šè¿‡ Docker å·å®ç°æ•°æ®æŒä¹…åŒ–ï¼š

```yaml
volumes:
  - ./articles:/app/articles        # çˆ¬å–çš„æ–‡ç« 
  - ./logs:/app/logs                # æ—¥å¿—æ–‡ä»¶
  - ./.env:/app/.env                # ç¯å¢ƒé…ç½®
```

æ•°æ®å°†è¢«ä¿å­˜åœ¨ä¸»æœºçš„ `articles/` å’Œ `logs/` ç›®å½•ä¸­ã€‚

---

## é…ç½®ç®¡ç†

### ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰

æ‰€æœ‰é…ç½®é€šè¿‡ `.env` æ–‡ä»¶ç®¡ç†ï¼ˆv2.0 å¼€å§‹ï¼‰ï¼š

```bash
cp .env.example .env
# ç¼–è¾‘é…ç½®
```

è¯¦è§ [CONFIG.md](CONFIG.md)

### ä¸»è¦é…ç½®é¡¹

```env
# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO

# Dify Workflowï¼ˆAI åˆ†æï¼‰
DIFY_ENABLED=false
DIFY_API_ENDPOINT=http://localhost:8001/v1
DIFY_API_KEY=your-api-key

# Gemini APIï¼ˆAI æ¨¡å‹ï¼‰
GEMINI_API_KEY=your-api-key
GEMINI_MODEL=gemini-2.5-flash

# ç”¨æˆ·èµ„æ–™ï¼ˆç”¨äº AI åˆ†æï¼‰
USER_PROFILE='{"education": {...}, "interests": {...}}'
```

è¯¦ç»†é…ç½®è¯´æ˜è§ [CONFIG.md](CONFIG.md)

---

## å¸¸è§é—®é¢˜

### Q1: CLI ç‰ˆæœ¬å’ŒæœåŠ¡ç‰ˆæœ¬çš„åŒºåˆ«ï¼Ÿ

| ç‰¹æ€§ | CLI ç‰ˆæœ¬ | æœåŠ¡ç‰ˆæœ¬ |
|------|---------|---------|
| å¯åŠ¨æ–¹å¼ | äº¤äº’èœå• | åå°æœåŠ¡ |
| ä½¿ç”¨åœºæ™¯ | æœ¬åœ°å¼€å‘/æµ‹è¯• | å®¹å™¨éƒ¨ç½² |
| å®šæ—¶ä»»åŠ¡ | âŒ | âœ… |
| REST API | âŒ | âœ… |
| Web UI | âœ… å¯é€‰å¯åŠ¨ | âœ… è‡ªåŠ¨å¯åŠ¨ |

### Q2: å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æŒç»­è¿è¡Œï¼Ÿ

**æ¨èæ–¹æ¡ˆï¼š**

```bash
# æ–¹æ¡ˆ 1: Docker Compose
docker-compose up -d service

# æ–¹æ¡ˆ 2: systemd serviceï¼ˆLinuxï¼‰
sudo vim /etc/systemd/system/sztu-scraper.service
# é…ç½®å¹¶å¯åŠ¨
sudo systemctl start sztu-scraper
sudo systemctl enable sztu-scraper

# æ–¹æ¡ˆ 3: åå°è¿›ç¨‹
nohup python service_entry.py > logs/service.log 2>&1 &
```

### Q3: å¦‚ä½•è°ƒæ•´å®šæ—¶ä»»åŠ¡çš„é¢‘ç‡ï¼Ÿ

ç¼–è¾‘ `.env` æ–‡ä»¶ä¸­çš„è°ƒåº¦é…ç½®æˆ–å‚è€ƒ [CONFIG.md](CONFIG.md)

### Q4: å¦‚ä½•æŸ¥çœ‹æ—¥å¿—ï¼Ÿ

```bash
# CLI ç‰ˆæœ¬ï¼šè¾“å‡ºåˆ°æ§åˆ¶å°

# æœåŠ¡ç‰ˆæœ¬ï¼š
docker-compose logs -f service
# æˆ–æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
tail -f logs/application.log
```

### Q5: å¦‚ä½•é‡ç½®æ•°æ®ï¼Ÿ

```bash
# ä¿ç•™é…ç½®ï¼Œåˆ é™¤çˆ¬å–çš„æ–‡ç« å’Œåˆ†æç»“æœ
rm -rf articles logs data

# ä½¿ç”¨ Docker Compose
docker-compose down -v              # åˆ é™¤æ‰€æœ‰å·
docker-compose up -d service        # é‡æ–°å¯åŠ¨
```

### Q6: æ”¯æŒå“ªäº› Python ç‰ˆæœ¬ï¼Ÿ

- Python 3.8+ï¼ˆæ¨è Python 3.10+ï¼‰
- ä½¿ç”¨ `python --version` æ£€æŸ¥

### Q7: å¦‚ä½•æ›´æ–°é¡¹ç›®ï¼Ÿ

```bash
git pull origin main
docker-compose build --no-cache
docker-compose up -d service
```

---

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. è°ƒæ•´çˆ¬è™«å¹¶å‘åº¦

ç¼–è¾‘ `.env` ä¸­çš„ `SCRAPER_CONCURRENT_REQUESTS` å‚æ•°

### 2. å®šæ—¶ä»»åŠ¡ä¼˜åŒ–

- é¿å…åœ¨ä¸šåŠ¡é«˜å³°æœŸçˆ¬å–
- è®¾ç½®åˆç†çš„è¯·æ±‚é—´éš”ï¼Œå°Šé‡ç›®æ ‡ç½‘ç«™

### 3. å­˜å‚¨ä¼˜åŒ–

- å®šæœŸæ¸…ç†è¿‡æœŸçš„åˆ†æç»“æœ
- è€ƒè™‘ä½¿ç”¨æ•°æ®åº“å­˜å‚¨å¤§é‡æ–‡ç« 

### 4. èµ„æºé™åˆ¶ï¼ˆDockerï¼‰

ç¼–è¾‘ `docker-compose.yml`ï¼š

```yaml
service:
  resources:
    limits:
      cpus: '1'
      memory: 1G
    reservations:
      cpus: '0.5'
      memory: 512M
```

---

## æ•…éšœæ’é™¤

### é—®é¢˜: çˆ¬å–è¶…æ—¶

**è§£å†³:**
1. æ£€æŸ¥ç½‘ç»œè¿æ¥
2. å¢åŠ  `SCRAPER_TIMEOUT` å‚æ•°
3. å‡å°‘ `SCRAPER_CONCURRENT_REQUESTS`

### é—®é¢˜: å†…å­˜ä¸è¶³

**è§£å†³:**
1. å‡å°‘å¹¶å‘æ•°
2. å®šæœŸæ¸…ç†ç¼“å­˜
3. å¢åŠ  Docker å†…å­˜é™åˆ¶

### é—®é¢˜: API æ— æ³•è®¿é—®

**è§£å†³:**
```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker-compose ps

# æ£€æŸ¥æ—¥å¿—
docker-compose logs api

# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep 8000
```

---

## ç›‘æ§å’Œå¥åº·æ£€æŸ¥

### å¥åº·æ£€æŸ¥

```bash
# æ£€æŸ¥ API å¥åº·çŠ¶æ€
curl http://localhost:8000/health

# æ£€æŸ¥ Web UI
curl http://localhost:8501/_stcore/health

# Docker Compose è‡ªåŠ¨å¥åº·æ£€æŸ¥
docker-compose ps
```

### æ—¥å¿—ç›‘æ§

```bash
# å®æ—¶ç›‘æ§æ—¥å¿—
tail -f logs/application.log

# æŸ¥çœ‹ç‰¹å®šæ—¥æœŸçš„æ—¥å¿—
grep "2024-01-15" logs/application.log
```

---

æ›´æ–°æ—¶é—´ï¼š2024 å¹´ 1 æœˆ
ç‰ˆæœ¬ï¼šv2.0

### schedule_config.json é…ç½®

```json
{
  "scheduler": {
    "scraper": {
      "enabled": true,
      "schedule": {
        "trigger": "cron",
        "hour": 0,
        "minute": 0
      },
      "params": {
        "pages": 3
      }
    },
    "analyzer": {
      "enabled": true,
      "schedule": {
        "trigger": "cron",
        "hour": 6,
        "minute": 0
      },
      "params": {
        "batch_size": 10
      }
    }
  }
}
```

### .env ç¯å¢ƒå˜é‡

```bash
# Dify é…ç½®
DIFY_ENABLED=false
DIFY_API_ENDPOINT=http://localhost:8001/v1
DIFY_API_KEY=your-api-key

# Gemini é…ç½®
GEMINI_API_KEY=your-api-key

# æ—¥å¿—çº§åˆ«
LOG_LEVEL=INFO

# è°ƒåº¦å™¨é…ç½®
SCHEDULER_ENABLED=true
SCHEDULER_TIMEZONE=Asia/Shanghai

# Web åº”ç”¨é…ç½®
WEB_HOST=0.0.0.0
WEB_PORT=8501
```

## éƒ¨ç½²æ¨¡å¼å¯¹æ¯”

| ç‰¹æ€§ | CLI æ¨¡å¼ | å•å®¹å™¨æ¨¡å¼ | å¤šå®¹å™¨æ¨¡å¼ |
|------|--------|---------|---------|
| å¯åŠ¨æ–¹å¼ | `python run.py` | `python run.py --mode service` | `docker-compose up` |
| è¿›ç¨‹ç®¡ç† | æ‰‹åŠ¨ | Supervisor | Docker |
| æ‰©å±•æ€§ | ä½ | ä¸­ | é«˜ |
| èµ„æºå ç”¨ | ä½ | ä½ | ä¸­ |
| é€‚ç”¨åœºæ™¯ | å¼€å‘ | å°è§„æ¨¡ | ç”Ÿäº§ |
| éƒ¨ç½²éš¾åº¦ | ç®€å• | ä¸­ç­‰ | ç®€å• |

## åœ¨çº¿è¿è¡Œç›‘æ§

### æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€

åœ¨ CLI æ¨¡å¼ä¸­ï¼š
```
é€‰é¡¹ 6 -> AI åˆ†æ -> 3 æŸ¥çœ‹åˆ†æå†å²
```

åœ¨ Web åº”ç”¨ä¸­ï¼š
- è®¿é—® `http://localhost:8501`
- åˆ‡æ¢åˆ° "ğŸ“Š åˆ†æç»“æœ" æ ‡ç­¾

### Docker ä¸­æŸ¥çœ‹æ—¥å¿—

```bash
# æŸ¥çœ‹è°ƒåº¦å™¨æ—¥å¿—
docker logs -f sztu-scraper-scheduler

# æŸ¥çœ‹ Web åº”ç”¨æ—¥å¿—
docker logs -f sztu-scraper-web

# å®æ—¶ç›‘æ§
docker stats
```

## å¸¸è§é—®é¢˜

### 1. Dify API è¿æ¥å¤±è´¥

**ç—‡çŠ¶ï¼š** åˆ†æä»»åŠ¡æŠ¥é”™ "è¿æ¥ Dify API å¤±è´¥"

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥ `DIFY_API_ENDPOINT` æ˜¯å¦æ­£ç¡®
- æ£€æŸ¥ `DIFY_API_KEY` æ˜¯å¦æœ‰æ•ˆ
- ç¡®ä¿ Dify æœåŠ¡æ­£åœ¨è¿è¡Œï¼š`curl http://localhost:8001/v1/workflows`

### 2. çˆ¬è™«ä»»åŠ¡å¤±è´¥

**ç—‡çŠ¶ï¼š** çˆ¬è™«ä»»åŠ¡æŠ¥é”™ï¼Œæ— æ³•è·å–æ–°é—»

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- æ£€æŸ¥ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®
- æŸ¥çœ‹ä»£ç†é…ç½®ï¼ˆå¦‚æœä½¿ç”¨ä»£ç†ï¼‰
- æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ï¼š`data/logs/`

### 3. å®¹å™¨å¯åŠ¨å¤±è´¥

**ç—‡çŠ¶ï¼š** `docker-compose up` å¤±è´¥

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æŸ¥çœ‹è¯¦ç»†é”™è¯¯
docker-compose up --no-detach

# æ£€æŸ¥ä¾èµ–
docker ps -a

# æ¸…ç†æ—§å®¹å™¨
docker-compose down -v
docker-compose up -d
```

### 4. æƒé™é”™è¯¯

**ç—‡çŠ¶ï¼š** "Permission denied" é”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# Linux/Mac
chmod +x services/*.py
chmod +x infrastructure/health-checks/*.py

# Docker
docker exec -u root sztu-scraper-scheduler chown -R 1000:1000 /app/data
```

### 5. å†…å­˜ä¸è¶³

**ç—‡çŠ¶ï¼š** å®¹å™¨è¢«æ€æ­»ï¼Œæ—¥å¿—æ˜¾ç¤º "Killed"

**è§£å†³æ–¹æ¡ˆï¼š**
```yaml
# docker-compose.yml ä¸­æ·»åŠ èµ„æºé™åˆ¶
services:
  scheduler:
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
```

## æ€§èƒ½ä¼˜åŒ–

### 1. çˆ¬è™«æ€§èƒ½

```json
{
  "scraper": {
    "params": {
      "pages": 10,           // å¢åŠ çˆ¬å–é¡µæ•°
      "timeout": 30,         // å¢åŠ è¶…æ—¶æ—¶é—´
      "retry_times": 5       // å¢åŠ é‡è¯•æ¬¡æ•°
    }
  }
}
```

### 2. åˆ†ææ€§èƒ½

```json
{
  "analyzer": {
    "params": {
      "batch_size": 50,      // å¢åŠ æ‰¹å¤„ç†å¤§å°
      "concurrent": 5        // å¹¶å‘æ•°ï¼ˆå¦‚æœæ”¯æŒï¼‰
    }
  }
}
```

### 3. æ•°æ®åº“ä¼˜åŒ–

ä½¿ç”¨ PostgreSQL æ›¿ä»£ SQLiteï¼š
```bash
DATABASE_URL=postgresql://user:password@localhost/sztu_scraper
```

## å¤‡ä»½ä¸æ¢å¤

### å¤‡ä»½æ•°æ®

```bash
# å¤‡ä»½æ‰€æœ‰æ•°æ®
docker-compose exec scheduler tar czf /app/data/backup.tar.gz \
  /app/data/articles \
  /app/data/logs

# å¤åˆ¶åˆ°æœ¬åœ°
docker cp sztu-scraper-scheduler:/app/data/backup.tar.gz ./
```

### æ¢å¤æ•°æ®

```bash
# å¤åˆ¶å¤‡ä»½åˆ°å®¹å™¨
docker cp backup.tar.gz sztu-scraper-scheduler:/app/data/

# è§£å‹
docker-compose exec scheduler tar xzf /app/data/backup.tar.gz -C /
```

## ç”Ÿäº§ç¯å¢ƒæ£€æŸ¥æ¸…å•

- [ ] é…ç½® `config.json` ä¸­çš„æ‰€æœ‰å¿…éœ€é¡¹
- [ ] é…ç½® `.env` ç¯å¢ƒå˜é‡
- [ ] æµ‹è¯• Dify API è¿æ¥
- [ ] æµ‹è¯• Gemini API è¿æ¥
- [ ] é…ç½®å®šæ—¶ä»»åŠ¡æ—¶é—´
- [ ] è®¾ç½®æ—¥å¿—çº§åˆ«ä¸º INFO æˆ– WARNING
- [ ] é…ç½®å¤‡ä»½ç­–ç•¥
- [ ] è®¾ç½®ç›‘æ§å‘Šè­¦
- [ ] å‡†å¤‡ç¾éš¾æ¢å¤æ–¹æ¡ˆ
- [ ] è¿›è¡Œè´Ÿè½½æµ‹è¯•

## ç›‘æ§ä¸å‘Šè­¦

### Prometheus æŒ‡æ ‡ï¼ˆå¯é€‰ï¼‰

```bash
# åœ¨ Dockerfile ä¸­æ·»åŠ 
RUN pip install prometheus-client

# åœ¨åº”ç”¨ä¸­æ·»åŠ æŒ‡æ ‡æ”¶é›†
from prometheus_client import Counter, Histogram

scraper_tasks = Counter('scraper_tasks_total', 'Total scraper tasks')
analysis_duration = Histogram('analysis_duration_seconds', 'Analysis duration')
```

### å‘Šè­¦è§„åˆ™ï¼ˆå¯é€‰ï¼‰

```yaml
# alerting_rules.yml
groups:
  - name: scraper
    rules:
      - alert: ScraperTaskFailed
        expr: increase(scraper_tasks_failed_total[5m]) > 0
        annotations:
          summary: "Scraper task failed"
```

## æŠ€æœ¯æ”¯æŒ

- æŸ¥çœ‹æ—¥å¿—ï¼š`docker logs sztu-scraper-scheduler`
- æ£€æŸ¥é…ç½®ï¼š`python run.py --info`
- æäº¤é—®é¢˜ï¼š[GitHub Issues](https://github.com/Hotpotfishsummer/HPF-SztuNewsScraper/issues)
